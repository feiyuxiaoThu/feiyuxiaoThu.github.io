---
title: 一周总结与回顾-5
date: 2024-12-01 12:59:12
tags:
  - summary
---

> 我以与外界交互的方式，认识我自己。

## 做了什么

- 赶 ddl，顺便把之前落下的课全部学完了
- 怀疑自己的科研工作到底会不会有结果，思考是否需要停止
- 体测，测完之后全身非常痛，应该是太久没有锻炼的原因。

我想详细分析一下科研的进展。

## 科研

说实话，我一直没有对手上的课题有一个清晰的认知，处于半朦胧的状态，可能的原因是

1. 可能科研本身就具有强烈的不确定性，在发现特殊的性质/认清解决的问题之前，会经过一段寻找方向的时期；
2. 我太菜了，不具备解决这个问题的能力。

大体目标是想做一个和任务相关的模态划分工作，但是我一直不清楚该怎么做，相关能够借鉴和参考的文章也只有寥寥两三篇，比如说之前这篇：[What is multimodality?](https://kinnariyamamatanha.github.io/blogs/2024/11/29/%E8%AE%BA%E6%96%87%E3%80%8AWhat-is-multimodality-%E3%80%8B/)。另外，我大概是在一个半月之前算正式开始接触多模态，这一个半月以来：

- 最初，我认为应该从模态的对齐出发，寻找不同模态的相同点和不同点，从而能够将相同部分作为一个模态，不同的部分作为另一个模态，比方说有两个模态 $f_1$ 和 $f_2$，可以把 $f_1 \cap f_2$、$f_1 - f_2$ 以及 $f_2 - f_1$ 作为三个模态。但这并不能体现任务决定模态这件事，于是放弃。
- 然后，我意识到对于给定的任务 $\mathcal{T}$，区分两个模态是否本质上为一个模态其实是在看它们关于 $\mathcal{T}$ 是否具有相同的信息，即使具有不同的表现形式。从这点出发，我尝试寻找现有能够筛选信息的网络结构，发现 encoder-decoder 架构和对互信息做最小化/最大化的损失函数相结合可以在理论上实现这个效果。但是，当我开始尝试使用这种网络的时候，发现其实效果并不好，并不能达到预期。暂时还没有找到/想到其他具有这种效果的架构。另外，这种方式不能实现现有“模态”的分解任务，而只能从现有数据中提取出信息的能力。

再说说我对这个课题的感性理解。这其实是在做一个很了不起的任务，但是又是一个感觉上离现在很远的任务：找出人类处理多感官信号的更深层次的机制。人类的感官每时每刻都会接收非常多的信息，其中必然会包含大量噪音，以及和当前在做的事情无关的信息。但是人类是可以高效率地使用它们的，不会像现在的模型一样一股脑把所有信息全部输进去处理。换句话说，这个课题就是想让模型也具有和人类一样的信息筛选、处理能力。

至于理性分析：

- 首先模型需要有人类一样的感知能力，或者说是信息处理能力，这可以用当前的诸多大模型进行表达——可以认为一些文本大模型、图像大模型等已经具备了和人类一样的特征提取能力。所以，为了实现任务决定模态这个目标，必须要使用大模型作为 representation encoder 的角色。
- 然后，在当前的模态定义下，任意一个模态（为了方便，下面我统一用**输入**来代指现有定义下的模态）必然包含多种信息，对于每一个指定的任务，其中只有一部分信息是有用的，我们把这些信息称作一个**模态**。
- 必然存在这样一个问题：这些信息是可分的吗？也就是说，是否有某种离散的分类方式，或者某种连续的分类方式？
    - 如果有的话，这种**原子信息**理所应当被称为真正的**模态**，于是每一个输入其实都是一些原子信息的组合。那么如何准确地提取出这些原子信息呢？退一步讲，有没有必要提取（并分类）出这些原子信息呢？我认为当前的深度学习是不可能完成这两件事中的任何一件的。
    - 如果没有的话，那么每个输入包含的信息就只能被分为两类（或者三类）：和任务有关的、和任务无关的（、噪音）。在上面我已经提到过，现有的提取和任务有关信息的模型，简单架构的还不够强大，难以完成任务；复杂架构的，如大模型，虽然功能强大，但是需要大量数据进行训练，然而很多种类的输入并没有很大的数据集（如传感器信号等），因此也不适用。

我对这个课题的认知大概就到这一步，现在没有更进一步的想法了。

功利一点的想法，我在这个学期至寒假应该要有一篇产出（不需要是一作），但是显然，如果我继续这个课题的话，极大概率是没有的，我应该好好思考一下有没有必要继续跟进这个课题。

## 碎碎念

这几天怎么 HuggingFace 连不上啊，换梯子也连不上，数据集和模型都下载不了，好烦啊🤬🤬🤬。

