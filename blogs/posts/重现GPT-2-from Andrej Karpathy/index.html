<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Tendourisu 的个人网站"><meta name=author content=Tendourisu><link href=https://tendourisu.github.io/blogs/posts/%E9%87%8D%E7%8E%B0GPT-2-from%20Andrej%20Karpathy/ rel=canonical><link rel=icon href=../../../img/aris.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.9"><title>重现GPT-2-from Andrej Karpathy - Tendourisu's Site</title><link rel=stylesheet href=../../../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=JetBrains+Mono:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"JetBrains Mono";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../css/custom.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=../../../css/fold_toc.css><link rel=stylesheet href=../../../css/card.css><link rel=stylesheet href=../../../css/flink.css><link rel=stylesheet href=../../../css/tasklist.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#gpt-2-124m class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Tendourisu's Site" class="md-header__button md-logo" aria-label="Tendourisu's Site" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Tendourisu's Site </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 重现GPT-2-from Andrej Karpathy </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo aria-label="light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="dark mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Tendourisu/tendourisu.github.io/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Tendourisu's Site </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> Home </a> </li> <li class=md-tabs__item> <a href=../../../notes/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> Notes </a> </li> <li class=md-tabs__item> <a href=../../../summary/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> Summaries </a> </li> <li class=md-tabs__item> <a href=../../../Tools/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16h-2v-1H8v1H6v-1H2v5h20v-5h-4zm2-8h-3V6c0-1.1-.9-2-2-2H9c-1.1 0-2 .9-2 2v2H4c-1.1 0-2 .9-2 2v4h4v-2h2v2h8v-2h2v2h4v-4c0-1.1-.9-2-2-2m-5 0H9V6h6z"/></svg> Tools </a> </li> <li class=md-tabs__item> <a href=../../ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32m0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32m-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48z"/></svg> Blogs </a> </li> <li class=md-tabs__item> <a href=../../../tags/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5.5 7A1.5 1.5 0 0 1 4 5.5 1.5 1.5 0 0 1 5.5 4 1.5 1.5 0 0 1 7 5.5 1.5 1.5 0 0 1 5.5 7m15.91 4.58-9-9C12.05 2.22 11.55 2 11 2H4c-1.11 0-2 .89-2 2v7c0 .55.22 1.05.59 1.41l8.99 9c.37.36.87.59 1.42.59s1.05-.23 1.41-.59l7-7c.37-.36.59-.86.59-1.41 0-.56-.23-1.06-.59-1.42"/></svg> Tags </a> </li> <li class=md-tabs__item> <a href=../../../links/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> Links </a> </li> <li class=md-tabs__item> <a href=../../../about/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-91.9-186.5C182 346.2 212.6 368 256 368s74-21.8 91.9-42.5c5.8-6.7 15.9-7.4 22.6-1.6s7.4 15.9 1.6 22.6c-22.3 25.6-61 53.5-116.1 53.5s-93.8-27.9-116.1-53.5c-5.8-6.7-5.1-16.8 1.6-22.6s16.8-5.1 22.6 1.6M144.4 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m156.4 25.6c-5.3 7.1-15.3 8.5-22.4 3.2s-8.5-15.3-3.2-22.4c30.4-40.5 91.2-40.5 121.6 0 5.3 7.1 3.9 17.1-3.2 22.4s-17.1 3.9-22.4-3.2c-17.6-23.5-52.8-23.5-70.4 0"/></svg> About </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Tendourisu's Site" class="md-nav__button md-logo" aria-label="Tendourisu's Site" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> Tendourisu's Site </label> <div class=md-nav__source> <a href=https://github.com/Tendourisu/tendourisu.github.io/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Tendourisu's Site </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=../../../notes/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> <span class=md-ellipsis> Notes </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> CS61C </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> CS61C </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/cs61c/lec01-Intro/ class=md-nav__link> <span class=md-ellipsis> lec01-Intro </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec02-C%E5%9F%BA%E7%A1%801/ class=md-nav__link> <span class=md-ellipsis> lec02-C基础1 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec03-C%E5%9F%BA%E7%A1%802/ class=md-nav__link> <span class=md-ellipsis> lec03-C基础2 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec04-C%E5%9F%BA%E7%A1%803/ class=md-nav__link> <span class=md-ellipsis> lec04-C基础3 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec05-C%E6%B5%AE%E7%82%B9%E6%95%B0%E5%9F%BA%E7%A1%80/ class=md-nav__link> <span class=md-ellipsis> lec05-C浮点数基础 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec06-RISCV%E6%8C%87%E4%BB%A4%E5%9F%BA%E7%A1%801/ class=md-nav__link> <span class=md-ellipsis> lec06-RISCV指令基础1 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec07-RISCV%E6%8C%87%E4%BB%A4%E5%9F%BA%E7%A1%802/ class=md-nav__link> <span class=md-ellipsis> lec07-RISCV指令基础2 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec08-RISCV%E6%8C%87%E4%BB%A4%E6%80%BB%E7%BB%93/ class=md-nav__link> <span class=md-ellipsis> lec08-RISCV指令总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec09-RISC-V%E6%B1%87%E7%BC%96-%E7%BC%96%E8%AF%91-%E9%93%BE%E6%8E%A5%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93/ class=md-nav__link> <span class=md-ellipsis> lec09-lec09-RISC-V汇编-编译-链接流程总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec10-%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80/ class=md-nav__link> <span class=md-ellipsis> lec10-数字电路基础 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec11-%E6%97%B6%E5%BA%8F%E7%94%B5%E8%B7%AF%26%E6%A8%A1%E6%8B%9F%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80/ class=md-nav__link> <span class=md-ellipsis> lec11-时序电路&模拟电路基础 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec12-RISC-V%E5%A4%84%E7%90%86%E5%99%A8%E8%AE%BE%E8%AE%A1/ class=md-nav__link> <span class=md-ellipsis> lec12-RISC-V处理器设计 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec13-RISC-V%E7%9A%84%E6%8E%A7%E5%88%B6%E5%99%A8%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%85%A5%E9%97%A8/ class=md-nav__link> <span class=md-ellipsis> lec13-RISC-V的控制器实现与流水线入门 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec14-RISC-V%20%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%8E%E5%A4%84%E7%90%86%E5%99%A8/ class=md-nav__link> <span class=md-ellipsis> lec14-RISC-V 流水线与处理器 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec15-%E7%BC%93%E5%AD%98%E7%B3%BB%E7%BB%9F/ class=md-nav__link> <span class=md-ellipsis> lec15-缓存系统 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec16-%E7%BC%93%E5%AD%98%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/ class=md-nav__link> <span class=md-ellipsis> lec16-缓存系统总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/lec17-%E7%BC%93%E5%AD%98%E6%80%BB%E7%BB%93/ class=md-nav__link> <span class=md-ellipsis> lec17-缓存总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/cs61c/riscv%E4%BB%A3%E7%A0%81%E4%B9%A0%E6%83%AF/ class=md-nav__link> <span class=md-ellipsis> riscv代码习惯 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> easy-rl </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> easy-rl </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter1-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter1-强化学习基础 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter2-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8BMDP/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter2-马尔科夫决策过程MDP </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter3-%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%96%B9%E6%B3%95/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter3-表格型方法 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter4-%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter4-策略梯度 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter5-%E8%BF%91%E7%AB%AF%E7%AD%96%E7%95%A5%E4%BC%98%E5%8C%96PPO/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter5-近端策略优化PPO </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter6-DQN/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter6-DQN </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter7-DQN%E8%BF%9B%E9%98%B6%E6%8A%80%E5%B7%A7/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter7-DQN进阶技巧 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter8-%E9%92%88%E5%AF%B9%E8%BF%9E%E7%BB%AD%E5%8A%A8%E4%BD%9C%E7%9A%84%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter8-针对连续动作的深度Q网络 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/easy-rl-chapter9-%E6%BC%94%E5%91%98-%E8%AF%84%E8%AE%BA%E5%91%98%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/ class=md-nav__link> <span class=md-ellipsis> easy-rl-chapter9-演员-评论员算法总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/POMDP%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/ class=md-nav__link> <span class=md-ellipsis> POMDP的一些参数说明 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/RL%E5%85%A5%E9%97%A8%E6%B1%87%E6%80%BB/ class=md-nav__link> <span class=md-ellipsis> RL入门汇总 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/RLfromDeepSeek/ class=md-nav__link> <span class=md-ellipsis> RLfromDeepSeek </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/easy-rl/%E7%8E%8B%E6%A0%91%E6%A3%AEReinforcement_Learning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ class=md-nav__link> <span class=md-ellipsis> 王树森Reinforcement_Learning学习笔记 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> CS231N </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> CS231N </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/cs231n/cs231n/ class=md-nav__link> <span class=md-ellipsis> cs231n </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../../summary/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> <span class=md-ellipsis> Summaries </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Summaries </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 2025 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 2025 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/2025/2025-W08-02/ class=md-nav__link> <span class=md-ellipsis> 2025-W08-02 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/2025/2025-W09-02/ class=md-nav__link> <span class=md-ellipsis> 2025-W09-02 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/2025/2025-W11-03/ class=md-nav__link> <span class=md-ellipsis> 2025-W11-03 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/2025/2025-W12-03/ class=md-nav__link> <span class=md-ellipsis> 2025-W12-03 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../../../Tools/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16h-2v-1H8v1H6v-1H2v5h20v-5h-4zm2-8h-3V6c0-1.1-.9-2-2-2H9c-1.1 0-2 .9-2 2v2H4c-1.1 0-2 .9-2 2v4h4v-2h2v2h8v-2h2v2h4v-4c0-1.1-.9-2-2-2m-5 0H9V6h6z"/></svg> <span class=md-ellipsis> Tools </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Cheat Sheet </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Cheat Sheet </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/Tools%20%E5%BE%85%E6%95%B4%E7%90%86/ class=md-nav__link> <span class=md-ellipsis> Tools 待整理 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/ class=md-nav__link> <span class=md-ellipsis> 常用命令 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/ class=md-nav__link> <span class=md-ellipsis> 常用配置文件 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_5> <label class=md-nav__link for=__nav_4_2_5 id=__nav_4_2_5_label tabindex=0> <span class=md-ellipsis> tools </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_5> <span class="md-nav__icon md-icon"></span> tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/adb%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> adb Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/bash%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> bash Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/ffmpeg%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> ffmpeg Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/gdb%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> gdb Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/git%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> git </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/ip%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> ip Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/tmux%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> tmux Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/Docker%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Docker Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/KDE%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> KDE </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/Makeflie%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Makeflie </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/chezmoi%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> 完整的 Dotfiles 配置指南 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/mkdocs%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> mkdocs Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/network%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> network Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/ssh%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> SSH配置指南 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/tabby%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Tabby 终端配置完全指南 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/wandb%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> wandb Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/zotero%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> zotero 使用指南 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/%E5%B0%8F%E9%B9%A4%E5%8F%8C%E6%8B%BC%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> 小鹤双拼 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/tools/%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> 远程连接 Cheat Sheet </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_6> <label class=md-nav__link for=__nav_4_2_6 id=__nav_4_2_6_label tabindex=0> <span class=md-ellipsis> editors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_6> <span class="md-nav__icon md-icon"></span> editors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/emacs%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> emacs Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/nano%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> nano Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/VScode%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> VScode </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/org%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> org Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/vim%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> vim Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/nvim%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> nvim </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/editors/cursor%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> cursor </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_7> <label class=md-nav__link for=__nav_4_2_7 id=__nav_4_2_7_label tabindex=0> <span class=md-ellipsis> languages </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_7_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_7> <span class="md-nav__icon md-icon"></span> languages </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/javascript%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> javascript Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/python%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Python Numpy </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/vimscript%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> VimScript Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/Go%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> Go Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/markdown%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> markdown Cheat Sheet </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/languages/typst%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> typst Cheat Sheet </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_8> <label class=md-nav__link for=__nav_4_2_8 id=__nav_4_2_8_label tabindex=0> <span class=md-ellipsis> System </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_8> <span class="md-nav__icon md-icon"></span> System </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Cheat%20Sheet/System/Arch%20Cheat%20Sheet/ class=md-nav__link> <span class=md-ellipsis> arch 配置 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex=0> <span class=md-ellipsis> AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/AI/prompt/ class=md-nav__link> <span class=md-ellipsis> prompt </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/AI/prompt_writing/ class=md-nav__link> <span class=md-ellipsis> AI 使用 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex=0> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Blog/Mkdocs_Material/ class=md-nav__link> <span class=md-ellipsis> mkdocs material 超全配置 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_5> <label class=md-nav__link for=__nav_4_5 id=__nav_4_5_label tabindex=0> <span class=md-ellipsis> Environment </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_5_label aria-expanded=false> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Environment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Environment/Arch_setup/ class=md-nav__link> <span class=md-ellipsis> arch 配置 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Environment/Ubuntu_setup/ class=md-nav__link> <span class=md-ellipsis> Ubuntu 配置 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Environment/environment/ class=md-nav__link> <span class=md-ellipsis> Environment </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Environment/obsidian_setup/ class=md-nav__link> <span class=md-ellipsis> obsidian 配置 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_6> <label class=md-nav__link for=__nav_4_6 id=__nav_4_6_label tabindex=0> <span class=md-ellipsis> Make </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> Make </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Make/CMake/ class=md-nav__link> <span class=md-ellipsis> CMake 相关 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Make/Makeflie/ class=md-nav__link> <span class=md-ellipsis> Makeflie </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_7> <label class=md-nav__link for=__nav_4_7 id=__nav_4_7_label tabindex=0> <span class=md-ellipsis> Others </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_7_label aria-expanded=false> <label class=md-nav__title for=__nav_4_7> <span class="md-nav__icon md-icon"></span> Others </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Others/Chezmoi/ class=md-nav__link> <span class=md-ellipsis> 用 chezmoi 实现跨设备同步配置 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Others/SSH/ class=md-nav__link> <span class=md-ellipsis> SSH配置指南 </span> </a> </li> <li class=md-nav__item> <a href=../../../Tools/Others/zotero_%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/ class=md-nav__link> <span class=md-ellipsis> zotero_使用指南 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_8> <label class=md-nav__link for=__nav_4_8 id=__nav_4_8_label tabindex=0> <span class=md-ellipsis> Terminal </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_8_label aria-expanded=false> <label class=md-nav__title for=__nav_4_8> <span class="md-nav__icon md-icon"></span> Terminal </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Tools/Terminal/Tabby_Zsh/ class=md-nav__link> <span class=md-ellipsis> Tabby + Zsh 配置指南 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32m0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32m-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48z"/></svg> <span class=md-ellipsis> Blogs </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Blogs </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tags/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5.5 7A1.5 1.5 0 0 1 4 5.5 1.5 1.5 0 0 1 5.5 4 1.5 1.5 0 0 1 7 5.5 1.5 1.5 0 0 1 5.5 7m15.91 4.58-9-9C12.05 2.22 11.55 2 11 2H4c-1.11 0-2 .89-2 2v7c0 .55.22 1.05.59 1.41l8.99 9c.37.36.87.59 1.42.59s1.05-.23 1.41-.59l7-7c.37-.36.59-.86.59-1.41 0-.56-.23-1.06-.59-1.42"/></svg> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../links/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> <span class=md-ellipsis> Links </span> </a> </li> <li class=md-nav__item> <a href=../../../about/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-91.9-186.5C182 346.2 212.6 368 256 368s74-21.8 91.9-42.5c5.8-6.7 15.9-7.4 22.6-1.6s7.4 15.9 1.6 22.6c-22.3 25.6-61 53.5-116.1 53.5s-93.8-27.9-116.1-53.5c-5.8-6.7-5.1-16.8 1.6-22.6s16.8-5.1 22.6 1.6M144.4 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m156.4 25.6c-5.3 7.1-15.3 8.5-22.4 3.2s-8.5-15.3-3.2-22.4c30.4-40.5 91.2-40.5 121.6 0 5.3 7.1 3.9 17.1-3.2 22.4s-17.1 3.9-22.4-3.2c-17.6-23.5-52.8-23.5-70.4 0"/></svg> <span class=md-ellipsis> About </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 介绍与目标 </span> </a> </li> <li class=md-nav__item> <a href=#gpt-2 class=md-nav__link> <span class=md-ellipsis> 加载预训练的 GPT-2 模型 </span> </a> <nav class=md-nav aria-label="加载预训练的 GPT-2 模型"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 模型参数示例 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 文本生成示例 </span> </a> </li> <li class=md-nav__item> <a href=#gpt-2_1 class=md-nav__link> <span class=md-ellipsis> 从零开始实现 GPT-2 模型 </span> </a> </li> <li class=md-nav__item> <a href=#gpt-2-transformer class=md-nav__link> <span class=md-ellipsis> GPT-2 模型架构与原始 Transformer 的差异 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 实现模型组件 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 加载预训练权重到自定义模型 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 实现模型的前向传播 </span> </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 使用自定义模型生成文本 </span> </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 数据集准备 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 实现损失函数 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 实现优化过程 </span> </a> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 数据加载器的改进 </span> </a> </li> <li class=md-nav__item> <a href=#weight-tying class=md-nav__link> <span class=md-ellipsis> 权重绑定 (Weight Tying) </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 模型参数初始化 </span> </a> </li> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 硬件选择与利用 </span> </a> </li> <li class=md-nav__item> <a href=#mixed-precision-training class=md-nav__link> <span class=md-ellipsis> 混合精度训练 (Mixed Precision Training) </span> </a> </li> <li class=md-nav__item> <a href=#torch-compile class=md-nav__link> <span class=md-ellipsis> Torch Compile </span> </a> </li> <li class=md-nav__item> <a href=#flash-attention class=md-nav__link> <span class=md-ellipsis> Flash Attention </span> </a> </li> <li class=md-nav__item> <a href=#padding class=md-nav__link> <span class=md-ellipsis> Padding 优化 </span> </a> </li> <li class=md-nav__item> <a href=#distributed-training class=md-nav__link> <span class=md-ellipsis> 分布式训练 (Distributed Training) </span> </a> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 训练数据集 </span> </a> </li> <li class=md-nav__item> <a href=#fineweb class=md-nav__link> <span class=md-ellipsis> 改进的数据加载器以支持 FineWeb 数据 </span> </a> </li> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 训练过程与评估 </span> </a> </li> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 训练结果 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 后续步骤与相关项目 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <div><div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;"> <p><span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约 4828 个字 <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间 24 分钟 <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5"></path></svg></span> 共被读过 <span id=busuanzi_value_page_pv></span> 次</p> </div> <div class=md-typeset> <div class=blogging-tags-grid> <a href=https://tendourisu.github.io/tags#LLM class=blogging-tag><code>#LLM</code></a> </div> </div> <style>
    .md-typeset .blogging-tags-grid {
        display: flex;
        flex-direction: row;
        flex-wrap: wrap;
        gap: 8px;
        margin-top: 5px;
    }

    .md-typeset .blogging-tag {
        color: var(--md-typeset-color);
        background-color: var(--md-typeset-code-color);
        white-space: nowrap;
        display: block;
    }

    .md-typeset .blogging-tag code {
        border-radius: 5px;
    }
</style> <h1 id=gpt-2-124m>重现 GPT-2 (124M) 笔记<a class=headerlink href=#gpt-2-124m title="Permanent link">¶</a></h1> <div class="admonition meta"> <p class=admonition-title>Meta</p> <p>YouTube： <a href="https://www.youtube.com/watch?v=l8pRSuU81PU">Let's reproduce GPT-2 (124M) - YouTube</a> <br> bilibili： <a href=https://www.bilibili.com/video/BV12s421u7sZ>【精校】“让我们重现GPT-2（1.24亿参数）!”AI大神Andrej Karpathy最新4小时经典教程 【中英】_哔哩哔哩_bilibili</a></p> </div> <h2 id=_1>介绍与目标<a class=headerlink href=#_1 title="Permanent link">¶</a></h2> <ul> <li>本视频是 "Zero to Hero" 系列的延续，目标是<strong>重现 GPT-2 的 1.24 亿参数版本</strong>。</li> <li>OpenAI 于 2019 年发布了 GPT-2，包括<strong>博客文章、论文和 GitHub 代码</strong> (openai/gpt-2)。</li> <li>GPT-2 有一个<strong>模型系列</strong>，包含不同大小的模型，最大的通常被称为 GPT-2。</li> <li>模型大小与下游任务（如翻译、摘要、问答）的性能之间存在<strong>缩放规律</strong>，即模型越大，性能越好。</li> <li>GPT-2 系列包含<strong>四个模型</strong>，参数量从 1.24 亿到 15.58 亿不等。</li> <li>1.24 亿参数模型拥有 <strong>12 个 Transformer 层</strong>和 <strong>768 个通道（维度）</strong>。</li> <li>本视频假设观众对 Transformer 的基本概念有一定的了解，这些内容在之前的 "Let's build GPT from scratch" 视频中已涵盖。</li> <li>目标是通过从零开始训练，最终达到甚至<strong>超过</strong> OpenAI 发布的 1.24 亿参数 GPT-2 模型的性能，通过<strong>验证损失</strong>来衡量.</li> <li>如今，重现该模型大约只需要<strong>一小时</strong>和 <strong>10 美元</strong>的云 GPU 计算成本。</li> <li>OpenAI <strong>发布了 GPT-2 的模型权重</strong>。</li> <li>GPT-2 论文在训练细节方面不够完善，因此还会参考<strong>GPT-3 论文</strong>，后者在超参数和优化设置等方面更加具体，且架构与 GPT-2 差异不大.</li> <li>首先会<strong>加载 OpenAI 发布的 GPT-2 124M 模型</strong>，并进行简单的文本生成，作为目标参考.</li> </ul> <h2 id=gpt-2>加载预训练的 GPT-2 模型<a class=headerlink href=#gpt-2 title="Permanent link">¶</a></h2> <ul> <li>原始 GPT-2 代码使用 <strong>TensorFlow</strong> 编写，但为了方便起见，本视频将使用 <strong>PyTorch</strong>.</li> <li>使用 <strong>Hugging Face Transformers</strong> 库可以轻松加载和使用 GPT-2 的 PyTorch 实现.</li> <li>Hugging Face 已经完成了将 TensorFlow 权重转换为 PyTorch 格式的工作.</li> <li>通过 <code>transformers</code> 库可以加载 <code>GPT2LMHeadModel</code>.</li> <li>需要注意的是，使用 <code>gpt2</code> 作为预训练模型名称时，实际加载的是 <strong>1.24 亿参数模型</strong>，而 <code>gpt2-xl</code> 才是 15 亿参数模型.</li> <li>可以获取模型的 <code>state_dict</code>，其中包含原始的张量权重.</li> <li>查看 <code>state_dict</code> 可以了解模型中不同参数的名称和形状.</li> </ul> <h3 id=_2>模型参数示例<a class=headerlink href=#_2 title="Permanent link">¶</a></h3> <ul> <li><code>wte.weight</code>: <strong>词嵌入</strong> (Token Embedding) 的权重，形状为 ``，其中 50257 是 GPT-2 的<strong>词汇表大小</strong>，768 是每个词嵌入的维度.<ul> <li>GPT-2 的 tokenizer 具有 50257 个 tokens，这些 tokens 在之前的 <strong>tokenization 系列视频</strong>中有详细介绍.</li> <li>每个 token 都由一个 768 维的向量表示.</li> </ul> </li> <li><code>wpe.weight</code>: <strong>位置嵌入</strong> (Position Embedding) 的权重，形状为 ``，GPT-2 的最大序列长度为 1024.<ul> <li>每个位置都有一个 768 维的固定向量表示，通过优化学习得到.</li> <li>位置嵌入学习到了类似<strong>正弦和余弦</strong>的结构.</li> <li>与原始 Transformer 中固定的位置编码不同，GPT-2 中的位置嵌入是<strong>可学习的参数</strong>.</li> </ul> </li> <li>其他参数包括 Transformer 层的权重和偏置等.</li> </ul> <details class=model> <summary>Model</summary> <p>transformer.wte.weight torch.Size([50257, 768])<br> transformer.wpe.weight torch.Size([1024, 768])<br> transformer.h.0.ln_1.weight torch.Size([768])<br> transformer.h.0.ln_1.bias torch.Size([768])<br> transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.0.attn.c_attn.bias torch.Size([2304])<br> transformer.h.0.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.0.attn.c_proj.bias torch.Size([768])<br> transformer.h.0.ln_2.weight torch.Size([768])<br> transformer.h.0.ln_2.bias torch.Size([768])<br> transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.0.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.0.mlp.c_proj.bias torch.Size([768])<br> transformer.h.1.ln_1.weight torch.Size([768])<br> transformer.h.1.ln_1.bias torch.Size([768])<br> transformer.h.1.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.1.attn.c_attn.bias torch.Size([2304])<br> transformer.h.1.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.1.attn.c_proj.bias torch.Size([768])<br> transformer.h.1.ln_2.weight torch.Size([768])<br> transformer.h.1.ln_2.bias torch.Size([768])<br> transformer.h.1.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.1.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.1.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.1.mlp.c_proj.bias torch.Size([768])<br> transformer.h.2.ln_1.weight torch.Size([768])<br> transformer.h.2.ln_1.bias torch.Size([768])<br> transformer.h.2.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.2.attn.c_attn.bias torch.Size([2304])<br> transformer.h.2.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.2.attn.c_proj.bias torch.Size([768])<br> transformer.h.2.ln_2.weight torch.Size([768])<br> transformer.h.2.ln_2.bias torch.Size([768])<br> transformer.h.2.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.2.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.2.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.2.mlp.c_proj.bias torch.Size([768])<br> transformer.h.3.ln_1.weight torch.Size([768])<br> transformer.h.3.ln_1.bias torch.Size([768])<br> transformer.h.3.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.3.attn.c_attn.bias torch.Size([2304])<br> transformer.h.3.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.3.attn.c_proj.bias torch.Size([768])<br> transformer.h.3.ln_2.weight torch.Size([768])<br> transformer.h.3.ln_2.bias torch.Size([768])<br> transformer.h.3.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.3.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.3.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.3.mlp.c_proj.bias torch.Size([768])<br> transformer.h.4.ln_1.weight torch.Size([768])<br> transformer.h.4.ln_1.bias torch.Size([768])<br> transformer.h.4.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.4.attn.c_attn.bias torch.Size([2304])<br> transformer.h.4.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.4.attn.c_proj.bias torch.Size([768])<br> transformer.h.4.ln_2.weight torch.Size([768])<br> transformer.h.4.ln_2.bias torch.Size([768])<br> transformer.h.4.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.4.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.4.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.4.mlp.c_proj.bias torch.Size([768])<br> transformer.h.5.ln_1.weight torch.Size([768])<br> transformer.h.5.ln_1.bias torch.Size([768])<br> transformer.h.5.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.5.attn.c_attn.bias torch.Size([2304])<br> transformer.h.5.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.5.attn.c_proj.bias torch.Size([768])<br> transformer.h.5.ln_2.weight torch.Size([768])<br> transformer.h.5.ln_2.bias torch.Size([768])<br> transformer.h.5.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.5.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.5.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.5.mlp.c_proj.bias torch.Size([768])<br> transformer.h.6.ln_1.weight torch.Size([768])<br> transformer.h.6.ln_1.bias torch.Size([768])<br> transformer.h.6.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.6.attn.c_attn.bias torch.Size([2304])<br> transformer.h.6.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.6.attn.c_proj.bias torch.Size([768])<br> transformer.h.6.ln_2.weight torch.Size([768])<br> transformer.h.6.ln_2.bias torch.Size([768])<br> transformer.h.6.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.6.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.6.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.6.mlp.c_proj.bias torch.Size([768])<br> transformer.h.7.ln_1.weight torch.Size([768])<br> transformer.h.7.ln_1.bias torch.Size([768])<br> transformer.h.7.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.7.attn.c_attn.bias torch.Size([2304])<br> transformer.h.7.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.7.attn.c_proj.bias torch.Size([768])<br> transformer.h.7.ln_2.weight torch.Size([768])<br> transformer.h.7.ln_2.bias torch.Size([768])<br> transformer.h.7.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.7.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.7.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.7.mlp.c_proj.bias torch.Size([768])<br> transformer.h.8.ln_1.weight torch.Size([768])<br> transformer.h.8.ln_1.bias torch.Size([768])<br> transformer.h.8.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.8.attn.c_attn.bias torch.Size([2304])<br> transformer.h.8.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.8.attn.c_proj.bias torch.Size([768])<br> transformer.h.8.ln_2.weight torch.Size([768])<br> transformer.h.8.ln_2.bias torch.Size([768])<br> transformer.h.8.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.8.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.8.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.8.mlp.c_proj.bias torch.Size([768])<br> transformer.h.9.ln_1.weight torch.Size([768])<br> transformer.h.9.ln_1.bias torch.Size([768])<br> transformer.h.9.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.9.attn.c_attn.bias torch.Size([2304])<br> transformer.h.9.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.9.attn.c_proj.bias torch.Size([768])<br> transformer.h.9.ln_2.weight torch.Size([768])<br> transformer.h.9.ln_2.bias torch.Size([768])<br> transformer.h.9.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.9.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.9.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.9.mlp.c_proj.bias torch.Size([768])<br> transformer.h.10.ln_1.weight torch.Size([768])<br> transformer.h.10.ln_1.bias torch.Size([768])<br> transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.10.attn.c_attn.bias torch.Size([2304])<br> transformer.h.10.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.10.attn.c_proj.bias torch.Size([768])<br> transformer.h.10.ln_2.weight torch.Size([768])<br> transformer.h.10.ln_2.bias torch.Size([768])<br> transformer.h.10.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.10.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.10.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.10.mlp.c_proj.bias torch.Size([768])<br> transformer.h.11.ln_1.weight torch.Size([768])<br> transformer.h.11.ln_1.bias torch.Size([768])<br> transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])<br> transformer.h.11.attn.c_attn.bias torch.Size([2304])<br> transformer.h.11.attn.c_proj.weight torch.Size([768, 768])<br> transformer.h.11.attn.c_proj.bias torch.Size([768])<br> transformer.h.11.ln_2.weight torch.Size([768])<br> transformer.h.11.ln_2.bias torch.Size([768])<br> transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])<br> transformer.h.11.mlp.c_fc.bias torch.Size([3072])<br> transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])<br> transformer.h.11.mlp.c_proj.bias torch.Size([768])<br> transformer.ln_f.weight torch.Size([768])<br> transformer.ln_f.bias torch.Size([768])<br> lm_head.weight torch.Size([50257, 768])</p> </details> <details class="model explain" open=open> <summary>Model</summary> <ol> <li><strong>Embedding层</strong>：<br> - <code>wte</code>：词嵌入矩阵 [50257, 768]（50257是vocab size）<br> - <code>wpe</code>：位置编码矩阵 [1024, 768]（支持最大1024 token的序列）</li> <li><strong>12层Transformer Block</strong>（h.0到h.11）： 每层包含：<br> - <strong>LayerNorm</strong>：<code>ln_1</code>（自注意力前）和<code>ln_2</code>（前馈网络前）<br> - <strong>自注意力机制</strong>：<ul> <li><code>c_attn</code>：QKV投影矩阵 [768, 2304]（768*3=2304）</li> <li><code>c_proj</code>：输出投影矩阵 [768, 768]</li> <li><strong>前馈网络</strong>：</li> <li><code>c_fc</code>：扩展层 [768, 3072]（4倍扩展）</li> <li><code>c_proj</code>：收缩层 [3072, 768]</li> </ul> </li> <li><strong>最终组件</strong>：<br> - <code>ln_f</code>：输出层归一化<br> - <code>lm_head</code>：语言模型头 [50257, 768]（通常与wte共享权重）<br> 模型配置推测：</li> </ol> <ul> <li>隐藏层维度：768</li> <li>注意力头数：12头（2304 / 768 = 3）</li> <li>FFN维度：3072（768*4）</li> <li>最大上下文长度：1024</li> <li>层数：12层（h.0到h.11)</li> </ul> </details> <h2 id=_3>文本生成示例<a class=headerlink href=#_3 title="Permanent link">¶</a></h2> <ul> <li>使用 Hugging Face Transformers 提供的 <code>pipeline</code> 可以方便地进行文本采样生成.</li> <li>给定一个前缀 (e.g., "hello I'm a language model,"), 模型可以生成后续的文本.</li> <li>即使固定随机种子，生成的文本结果也可能与示例不同，这可能是由于代码更新所致.</li> <li>重要的是，即使是预训练模型也能生成<strong>连贯的文本</strong>.</li> </ul> <h2 id=gpt-2_1>从零开始实现 GPT-2 模型<a class=headerlink href=#gpt-2_1 title="Permanent link">¶</a></h2> <ul> <li>为了更深入地理解模型内部机制，将<strong>从零开始实现 GPT-2 模型</strong>.</li> <li>目标是将 OpenAI 发布的 GPT-2 124M 模型的权重加载到我们自己实现的模型类中，以验证实现的正确性.</li> <li>最终目标是从零开始初始化模型并进行训练.</li> </ul> <h2 id=gpt-2-transformer>GPT-2 模型架构与原始 Transformer 的差异<a class=headerlink href=#gpt-2-transformer title="Permanent link">¶</a></h2> <ul> <li>GPT-2 是一个 <strong>decoder-only Transformer</strong>，因此<strong>没有 encoder 部分</strong>.</li> <li><strong>交叉注意力机制 (cross-attention)</strong> 也被移除.</li> <li>与原始 Transformer 相比，GPT-2 的 <strong>Layer Normalization 的位置发生了变化</strong>，且<strong>添加了一个额外的 Layer Normalization 层</strong>.<ul> <li>原始 Transformer 的 Layer Normalization 位于多头注意力和前馈网络之后.</li> <li>GPT-2 将 Layer Normalization 移到了<strong>多头注意力和前馈网络之前</strong>.</li> <li>GPT-2 在<strong>最后一个自注意力模块之后添加了一个额外的 Layer Normalization 层</strong>，位于最终分类器之前.</li> </ul> </li> <li><strong>预归一化 (Pre-normalization)</strong> 结构被认为更优，因为它保持了<strong>干净的残差路径</strong>，有利于梯度流动.</li> <li>Transformer 的核心操作是<strong>多头注意力 (Multi-Head Attention)</strong> 和 <strong>多层感知机 (MLP)</strong>.<ul> <li><strong>注意力机制</strong>是 <strong>通信操作</strong>，允许序列中的 tokens 之间交换信息，是一种 <strong>reduce 操作</strong>.</li> <li><strong>MLP</strong> 在每个 token 上<strong>独立</strong>进行计算，没有 token 之间的信息交换，是一种 <strong>map 操作</strong>.</li> <li>Transformer 可以被看作是 <strong>map-reduce 操作的重复应用</strong>.</li> </ul> </li> </ul> <h2 id=_4>实现模型组件<a class=headerlink href=#_4 title="Permanent link">¶</a></h2> <ul> <li>使用 <code>nn.Module</code> 实现模型的各个组件，并尽量匹配 Hugging Face Transformers 的命名规范.</li> <li>模型的骨架结构 <code>GPT</code> 包含以下模块:<ul> <li><code>transformer</code>: 一个 <code>nn.ModuleDict</code>，包含模型的子模块。<ul> <li><code>wte</code>: <strong>Token Embedding</strong> (<code>nn.Embedding</code>)。</li> <li><code>wpe</code>: <strong>Position Embedding</strong> (<code>nn.Embedding</code>)。</li> <li><code>h</code>: 一个 <code>nn.ModuleList</code>，包含 <strong>N 层 Transformer Block</strong> (<code>Block</code>)，对于 124M 模型，N=12.</li> <li><code>ln_f</code>: 最终的 <strong>Layer Normalization</strong> (<code>nn.LayerNorm</code>).</li> </ul> </li> <li><code>lm_head</code>: <strong>语言模型头</strong>，一个线性层 (<code>nn.Linear</code>)，将隐藏层维度 (768) 映射到词汇表大小 (50257)，<strong>没有偏置</strong>.</li> </ul> </li> <li><strong>Transformer Block</strong> (<code>Block</code>) 的实现包含:<ul> <li>Layer Normalization (第一个)。</li> <li><strong>自注意力 (Self-Attention)</strong> 模块 (<code>CausalSelfAttention</code>)。</li> <li>Layer Normalization (第二个)。</li> <li><strong>MLP</strong> 模块 (<code>MLP</code>)。</li> <li><strong>残差连接</strong>.</li> </ul> </li> <li><strong>MLP</strong> 模块的实现包含两个线性投影层，中间夹着 <strong>GELU (Gaussian Error Linear Unit) 非线性激活函数</strong>.<ul> <li>GPT-2 使用 GELU 的近似版本 (<code>nn.GELU(approximate='tanh')</code>).</li> </ul> </li> <li><strong>自注意力 (CausalSelfAttention)</strong> 模块的实现:<ul> <li>将输入映射为 <strong>Query (Q), Key (K), Value (V)</strong> 向量。</li> <li>实现<strong>多头注意力机制</strong>，通过对 Q 和 K 进行点积计算注意力权重。</li> <li>应用 <strong>mask</strong> 确保每个 token 只能attend到之前的 tokens (因果关系)。</li> <li>使用 <strong>softmax</strong> 对注意力权重进行归一化。</li> <li>将注意力权重与 V 相乘，得到每个 token 的加权表示。</li> <li><strong>高效的 PyTorch 实现</strong> 使用 <code>transpose</code> 和 <code>split</code> 等操作来处理多头注意力，避免显式地为每个头创建单独的模块.</li> </ul> </li> </ul> <h2 id=_5>加载预训练权重到自定义模型<a class=headerlink href=#_5 title="Permanent link">¶</a></h2> <ul> <li>创建与 Hugging Face Transformers 模型结构相匹配的自定义 <code>GPT</code> 模型配置 (<code>GPTConfig</code>)，包括 <code>block_size</code> (最大序列长度)、<code>vocab_size</code>、<code>n_layer</code> (层数)、<code>n_head</code> (注意力头数) 和 <code>n_embd</code> (嵌入维度) 等.</li> <li>编写代码将 Hugging Face 预训练模型的 <code>state_dict</code> 中的权重复制到自定义 <code>GPT</code> 模型的对应参数中.</li> <li>需要<strong>忽略一些 buffers</strong> (例如 attention 的 <code>bias</code>).</li> <li>由于 TensorFlow 和 PyTorch 中权重的存储顺序可能不同，可能需要<strong>手动转置某些权重</strong>.</li> <li>实现 <code>from_pretrained</code> 类方法，方便从预训练模型加载权重.</li> </ul> <h2 id=_6>实现模型的前向传播<a class=headerlink href=#_6 title="Permanent link">¶</a></h2> <ul> <li>实现 <code>GPT</code> 模型的 <code>forward</code> 函数，接收 token indices 作为输入.</li> <li>在前向传播过程中:<ul> <li>获取 <strong>token embeddings</strong> 和 <strong>position embeddings</strong>。</li> <li>将两者<strong>相加</strong>。</li> <li>将结果依次通过 <strong>Transformer 的所有 Blocks</strong>。</li> <li>通过最终的 <strong>Layer Normalization</strong>。</li> <li>通过 <strong>语言模型头 (LM Head)</strong> 得到 <strong>logits</strong>，其形状为 <code>[B, T, vocab_size]</code>，表示序列中每个位置的下一个 token 的预测分数.</li> </ul> </li> </ul> <h2 id=_7>使用自定义模型生成文本<a class=headerlink href=#_7 title="Permanent link">¶</a></h2> <ul> <li>将模型设置为<strong>评估模式 (<code>model.eval()</code>)</strong>.</li> <li>将模型和输入数据移动到<strong>GPU (CUDA)</strong> 上进行加速.</li> <li>使用 OpenAI 的 <code>tiktoken</code> 库对输入前缀进行 <strong>tokenization</strong>.</li> <li>将 tokenized 的前缀转换为 <strong>PyTorch 张量</strong>，并复制多份形成一个 batch.</li> <li>实现<strong>文本生成循环</strong>，每一步都将当前序列输入模型，获取最后一个位置的 logits，通过 <strong>softmax</strong> 得到概率分布，然后从该分布中<strong>采样</strong>下一个 token，并将采样的 token 追加到序列中.</li> <li>可以使用 <strong>Top-K 采样</strong> (只考虑概率最高的 K 个 tokens) 来提高生成质量.</li> <li>使用 <code>tiktoken</code> 的 <code>decode</code> 函数将生成的 token IDs 转换回文本.</li> <li>最初的模型（加载预训练权重之前）会生成<strong>随机的文本</strong>.</li> <li>即使没有 GPU，也可以在 <strong>CPU</strong> 上运行代码，但速度会慢很多.</li> </ul> <h2 id=_8>数据集准备<a class=headerlink href=#_8 title="Permanent link">¶</a></h2> <ul> <li>使用 <strong>Tiny Shakespeare 数据集</strong> 进行简单的调试和开发.</li> <li>使用 <code>tiktoken</code> 对文本数据进行 tokenization.</li> <li>将一维的 token 序列重塑为<strong>二维的 batch 张量</strong> (<code>[B, T]</code>)，作为模型的输入.</li> <li><strong>目标标签 (target)</strong> 是输入序列中每个 token 的下一个 token.</li> </ul> <h2 id=_9>实现损失函数<a class=headerlink href=#_9 title="Permanent link">¶</a></h2> <ul> <li>修改模型的前向传播函数，使其在接收到目标标签时<strong>计算损失</strong>.</li> <li>使用 <strong>交叉熵损失函数 (<code>nn.functional.cross_entropy</code>)</strong> 来衡量模型的预测与真实标签之间的差异.</li> <li>交叉熵损失函数需要将 logits 张量和目标标签张量<strong>展平</strong>为二维和一维.</li> <li>可以计算<strong>随机初始化模型的预期损失</strong>，作为 sanity check. 对于一个拥有 50257 个词汇的均匀分布，预期损失约为 <code>log(50257)</code>，即约 10.82.</li> </ul> <h2 id=_10>实现优化过程<a class=headerlink href=#_10 title="Permanent link">¶</a></h2> <ul> <li>使用 <strong>AdamW 优化器</strong> (<code>torch.optim.AdamW</code>) 来更新模型参数.</li> <li>在每个优化步骤中:<ul> <li><strong>清空梯度</strong> (<code>optimizer.zero_grad()</code>).</li> <li>进行<strong>前向传播</strong>计算损失。</li> <li>进行<strong>反向传播</strong>计算梯度 (<code>loss.backward()</code>).</li> <li>使用优化器<strong>更新参数</strong> (<code>optimizer.step()</code>).</li> <li>打印当前的步数和损失值.</li> </ul> </li> <li>可以使用<strong>学习率调度器</strong> (例如 <code>torch.optim.lr_scheduler.CosineAnnealingLR</code>) 来在训练过程中调整学习率.</li> </ul> <h2 id=_11>数据加载器的改进<a class=headerlink href=#_11 title="Permanent link">¶</a></h2> <ul> <li>实现一个更完善的数据加载器，可以<strong>按 batch 从文本文件中读取数据</strong>.</li> <li>数据加载器需要能够处理<strong>不完整的 batch</strong>，并在到达文件末尾时<strong>循环</strong>回到文件开头.</li> <li>每次返回一个 batch 的输入 (<code>x</code>) 和对应的目标 (<code>y</code>).</li> </ul> <h2 id=weight-tying>权重绑定 (Weight Tying)<a class=headerlink href=#weight-tying title="Permanent link">¶</a></h2> <ul> <li>GPT-2 采用了<strong>权重绑定</strong> (weight tying) 的技巧，即<strong>词嵌入矩阵 (<code>wte.weight</code>) 和语言模型头的权重 (<code>lm_head.weight</code>) 共享相同的参数</strong>.</li> <li>这种做法源于 "Attention is All You Need" 论文及其之前的研究.</li> <li>直觉是<strong>语义相似的 tokens 应该在嵌入空间中靠近，并且在 Transformer 的输出层也应该具有相似的概率分布</strong>.</li> <li>通过共享权重，可以<strong>减少模型参数量</strong> (对于 124M 模型，可以节省约 30% 的参数).</li> <li>在代码中实现权重绑定，将 <code>lm_head.weight</code> 指向 <code>wte.weight</code> 的数据指针.</li> </ul> <h2 id=_12>模型参数初始化<a class=headerlink href=#_12 title="Permanent link">¶</a></h2> <ul> <li>GPT-2 的权重初始化遵循一定的策略.</li> <li>根据 OpenAI 发布的代码，<strong>Transformer 层的权重使用标准差为 0.02 的正态分布初始化，偏置初始化为 0</strong>.</li> <li><strong>Token embeddings 的标准差初始化为 0.02，position embeddings 的标准差初始化为 0.01</strong>.</li> <li>可以在自定义模型的初始化函数中实现这些初始化策略.</li> </ul> <h2 id=_13>硬件选择与利用<a class=headerlink href=#_13 title="Permanent link">¶</a></h2> <ul> <li>选择合适的硬件 (例如 <strong>NVIDIA GPU</strong>) 对于加速模型训练至关重要.</li> <li>了解所用 GPU 的<strong>计算能力 (Teraflops)</strong> 和 <strong>内存带宽</strong>.</li> <li>可以使用 <code>nvidia-smi</code> 命令查看 GPU 的使用情况.</li> </ul> <h2 id=mixed-precision-training>混合精度训练 (Mixed Precision Training)<a class=headerlink href=#mixed-precision-training title="Permanent link">¶</a></h2> <ul> <li>默认情况下，PyTorch 使用 <strong>float32 (FP32)</strong> 精度存储激活和参数.</li> <li><strong>混合精度训练</strong> (例如使用 <strong>TF32</strong> 或 <strong>BFloat16</strong>) 可以在不显著降低模型性能的情况下，<strong>加速计算并减少内存占用</strong>.</li> <li>NVIDIA GPU 的 <strong>Tensor Cores</strong> 可以加速低精度浮点运算.</li> <li><strong>TF32</strong> 是一种较低精度的格式，可以在 Ampere 架构的 GPU 上获得高达 8 倍的性能提升，且对 PyTorch 代码是<strong>透明的</strong>.</li> <li><strong>BFloat16 (BF16)</strong> 是另一种低精度格式，与 FP16 相比，BF16 保留了与 FP32 相同的<strong>指数范围</strong>，因此通常<strong>不需要梯度缩放</strong>，使用起来更简单.</li> <li>可以使用 <code>torch.autocast</code> 上下文管理器在 PyTorch 中启用混合精度训练，<strong>只需要修改 forward 传播和损失计算部分</strong>.</li> </ul> <h2 id=torch-compile>Torch Compile<a class=headerlink href=#torch-compile title="Permanent link">¶</a></h2> <ul> <li><strong><code>torch.compile</code></strong> 是 PyTorch 2.0 引入的一项技术，可以将 PyTorch 模型编译为<strong>优化的可执行代码</strong>，从而显著<strong>提高训练和推理速度</strong>.</li> <li><code>torch.compile</code> 可以分析整个模型，<strong>移除 Python 解释器</strong>的开销，并进行<strong>kernel fusion</strong> 等优化，减少 GPU 内存的读写次数.</li> </ul> <h2 id=flash-attention>Flash Attention<a class=headerlink href=#flash-attention title="Permanent link">¶</a></h2> <ul> <li><strong>Flash Attention</strong> 是一种<strong>更高效的注意力机制算法</strong>，通过<strong>kernel fusion</strong> 和<strong>在线 softmax</strong> 等技巧，<strong>减少了对高带宽内存 (HBM) 的访问</strong>，从而显著<strong>加速了注意力计算</strong>.</li> <li>即使 Flash Attention 的浮点运算次数可能更多，但由于减少了内存访问，因此速度更快.</li> <li>Flash Attention <strong>不显式地物化巨大的注意力矩阵</strong>，从而节省了大量内存.</li> <li>可以使用 PyTorch 的 <code>scaled_dot_product_attention</code> 函数来调用 Flash Attention.</li> </ul> <h2 id=padding>Padding 优化<a class=headerlink href=#padding title="Permanent link">¶</a></h2> <ul> <li>在处理序列长度不一致的 batch 时，通常需要进行 <strong>padding</strong>。</li> <li>某些硬件对特定的张量形状具有更高的效率。例如，NVIDIA GPU 在处理维度是 8 的倍数的张量时可能更高效.</li> <li>将词汇表大小 padding 到 8 的倍数 (例如从 50257 到 50304) 可以带来 <strong>4% 左右的性能提升</strong>.</li> </ul> <h2 id=distributed-training>分布式训练 (Distributed Training)<a class=headerlink href=#distributed-training title="Permanent link">¶</a></h2> <ul> <li>使用 <strong>分布式数据并行 (Distributed Data Parallel, DDP)</strong> 可以利用<strong>多个 GPU</strong> 加速训练.</li> <li>DDP 的基本原理是<strong>在每个 GPU 上运行相同的训练代码，处理不同的数据子集，然后在每个反向传播步骤之后对梯度进行平均</strong>.</li> <li>可以使用 <code>torch.distributed</code> 模块来实现 DDP，并通过 <code>torchrun</code> 命令启动多个训练进程.</li> <li>需要<strong>同步不同进程之间的损失值</strong>，以获得整个数据集上的平均损失.</li> <li>可以设置<strong>梯度累积 (gradient accumulation)</strong> 来模拟更大的 batch size.</li> </ul> <h2 id=_14>训练数据集<a class=headerlink href=#_14 title="Permanent link">¶</a></h2> <ul> <li>GPT-2 使用了 <strong>WebText</strong> 数据集，这是一个从未公开的数据集，通过抓取 Reddit 上的出站链接得到.</li> <li>GPT-3 使用了更广泛的数据集混合，包括 <strong>Common Crawl、WebText、Books 和 Wikipedia</strong> 等，但具体细节也未完全公开.</li> <li>一些高质量的开源替代数据集包括 <strong>Red Pajama、Slim Pajama 和 FineWeb 数据集</strong>.</li> <li><strong>FineWeb Edu</strong> 是一个高质量的教育内容子集，包含 1.3 万亿 tokens.</li> <li>本视频使用了 <strong>FineWeb Edu 的 100 亿 tokens 子样本</strong>进行训练.</li> <li>提供了一个脚本 (<code>prepare_data.py</code>) 用于<strong>下载、预处理和 tokenization FineWeb Edu 数据集</strong>，并将其保存为多个 shards.</li> <li>预处理过程包括在每个文档的开头添加 <strong>end-of-text token</strong>.</li> </ul> <h2 id=fineweb>改进的数据加载器以支持 FineWeb 数据<a class=headerlink href=#fineweb title="Permanent link">¶</a></h2> <ul> <li>修改数据加载器，使其能够<strong>加载 FineWeb 数据 shards</strong> (NumPy 文件).</li> <li>数据加载器需要能够<strong>遍历所有 shards</strong>，并在每个 shard 内部按 batch 读取数据.</li> <li>支持加载训练集和验证集.</li> </ul> <h2 id=_15>训练过程与评估<a class=headerlink href=#_15 title="Permanent link">¶</a></h2> <ul> <li>在训练循环中，定期<strong>评估验证损失</strong>和<strong>生成文本样本</strong>.</li> <li>为了更好地评估模型的性能，引入了 <strong>HellaSwag 评估基准</strong>.</li> <li><strong>HellaSwag</strong> 是一个句子补全多项选择题数据集，旨在测试模型的常识推理能力.</li> <li>可以通过计算模型在不同选项上的<strong>平均交叉熵损失</strong>来评估模型在 HellaSwag 上的性能.</li> <li>自定义了一个脚本 (<code>hellaswag.py</code>) 用于评估预训练的 GPT-2 模型在 HellaSwag 上的性能.</li> <li>GPT-2 124M 在 HellaSwag 上的准确率约为 <strong>29.5%</strong>.</li> <li>将 HellaSwag 评估集成到主要的训练脚本中，定期评估训练过程中的模型性能.</li> <li>在评估 HellaSwag 时，<strong>暂时禁用了 <code>torch.compile</code></strong>，因为存在兼容性问题.</li> <li>在训练过程中，定期<strong>保存模型检查点</strong>.</li> </ul> <h2 id=_16>训练结果<a class=headerlink href=#_16 title="Permanent link">¶</a></h2> <ul> <li>经过约 200 亿 tokens 的训练后，模型在验证集上的损失<strong>低于</strong> OpenAI GPT-2 124M 模型的水平.</li> <li>生成的文本样本也变得<strong>更加连贯</strong>.</li> <li>HellaSwag 准确率也逐渐提高.</li> </ul> <h2 id=_17>后续步骤与相关项目<a class=headerlink href=#_17 title="Permanent link">¶</a></h2> <ul> <li>当前的训练只是<strong>预训练</strong>阶段，要使其具备类似 ChatGPT 的对话能力，还需要进行<strong>微调 (fine-tuning)</strong>.</li> <li><strong>nanoGPT</strong> 是一个基于 PyTorch 的简洁的 GPT 模型实现，本视频的内容是构建 nanoGPT 的过程.</li> <li><strong>LLM.C</strong> 是一个使用纯 CUDA 实现的 GPT-2/GPT-3 训练框架，速度更快，nanoGPT 可以作为其 PyTorch 参考实现.</li> <li>LLM.C 在训练速度上优于 PyTorch 实现，但 PyTorch 是一个更通用的框架.</li> </ul></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="March 18, 2025 22:32:22">March 18, 2025 22:32:22</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="March 18, 2025 22:32:22">March 18, 2025 22:32:22</span> </span> </aside> <!-- Insert generated snippet here --> <script src=https://giscus.app/client.js data-repo=Tendourisu/Tendourisu.github.io data-repo-id=R_kgDOMhyGaQ data-category=Announcements data-category-id=DIC_kwDOMhyGac4Cnbam data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async>
    </script> <!-- Synchronize Giscus theme with palette --> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "transparent_dark"
                    : "light"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 - Present <a href=https://github.com/Tendourisu/ target=_blank rel=noopener>Tendourisu</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/Tendourisu/ target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=/img/qq.jpg target=_blank rel=noopener title=加加我的QQ class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704"/></svg> </a> <a href=/img/wechat.jpg target=_blank rel=noopener title=加加我的微信 class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"/></svg> </a> <a href=https://x.com/tendourisu target=_blank rel=noopener title=X class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://www.zhihu.com/people/tendourisu target=_blank rel=noopener title=Zhihu class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg> </a> <a href=mailto:2681708668@qq.com target=_blank rel=noopener title="send email to me!" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "header.autohide", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.path", "navigation.indexes", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script> <script src=../../../js/mathjax.js></script> <script src=../../../js/toc.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>